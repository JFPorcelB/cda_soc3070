---
title: "Ejercicio 6"
subtitle: "Ayudantía soc3070"
author: "Cantillan, R. | Bucca, M."
institute: "ISUC"
page-layout: article
date: today
date-format: short
number-sections: true
format:
  html:
    titlepage-logo: "images/uc-chile.png"
    logo-align: left
    logo-size: 1.5
    theme: 
      light: flatly
      dark: darkly
    toc: true
    toc_float: true
    toc-depth: 5
    toc-title: "En este ejercicio"
editor: visual
title-block-banner: true
title-block-style: default
title-block-categories: true
freeze: true
execute: 
  echo: fenced
  eval: true
  output: true
  warning: false
reference-location: margin
citation-location: margin
bibliography: catagorical_data.bib
#highlight-style: ayu-dark
#code-block-bg: "#2E2E2E"
#code-block-border-left: "#31BAE9"
---

<head><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"></head>

::: sidebar-icons
<a href="https://github.com/mebucca/cda_soc3070/blob/gh-pages/ayudantia/03_manipulacion/index.qmd"><i class="fab fa-github"></i> source </a> <!-- Otros íconos aquí -->
:::

<head>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">

```{=html}
<style>
    .sidebar-icons {
      display: flex;
      flex-direction: column;
      gap: 10px;
    }
    .sidebar-icons a {
      display: flex;
      align-items: center;
      text-decoration: none;
      color: #333;
    }
    .sidebar-icons i {
      margin-right: 10px;
    }
  </style>
```
</head>

En este ejercicio vamos a utilizar nuevamente ELSOC en su versión 2019. Esta vez nos preguntamos acerca de los determinantes que influten en la probabilidad de armar vinculos de confidencia con vecinos. La pregunta es del todo relevante, puesto que la mayoría de las veces los vínculos vecinales constituyen el contexto que da forma a la estructura de oportunidades de interacción con otros (as) en la vida cotidiana de las personas [@blauInequalityHeterogeneityPrimitive1977; @feldFocusedOrganizationSocial1981]. La especificidad de los vecindarios es que son contextos en los cuales la actividad e interacción social están fuertemente condicionados por la proximidad física y social [@feldSocialStructuralDeterminants1982]. Asimismo, suelen contener a otros focos de interacción [@feldFocusedOrganizationSocial1981] como escuelas o asociaciones voluntarias. Por esta razón, los barrios o vecindarios implican más oportunidades y probabilidades de encuentro y vinculación entre sus integrantes.

@wellmanArePersonalCommunities1996 y @fernandezReviewAmericanApartheid1993 indican que aún cuando los lazos locales generalmente sean débiles, son contactos frecuentes. Su mayor frecuencia deriva de la cantidad relativa de tiempo que pasamos en nuestros vecindarios y hogares. Razón por la cual puede ser inevitable el encuentro con aquellos con los cuales compartimos un vecindario. Si consideramos que los barrios y los lugares de trabajo suelen ser socialmente más homogéneos @feldFocusedOrganizationSocial1981, el predominio de este tipo de lazos puede indicar altos niveles de segregación y aislamiento social [@dipreteSegregationSocialNetworks2011; @masseyAmericanApartheidSegregation2003]. Por lo tanto, las áreas locales son un campo de investigación óptimo para estudiar cómo los extraños se convierten en amigos [@volkerSixteenMillionNeighbors2007] y para el estudio general de las desigualdades persistentes [@tillyDurableInequality2009].

¿sobre qué bases los individuos establecen o no relaciones de cercanía con sus vecinos? y, ¿por qué algunas personas los incluyen en sus redes y otras no?

En efecto el ejericio incluirá lo siguiente:

-   Creación de data frames diádico.
-   Creación de variable dependiente binaria.
-   Estimación de errores estándar robustos (dada la dependencia en la estructura de datos).
-   Estimación de un modelo de regresión logística con la variable dependiente a nivel de diáda (vecino o no vecino) y como variables dependientes atributos del ego (se pueden -o deben- incluir otros niveles como el barrial, y caracteírticas de los alteris).

En la sesión del miércoles 26 de septiembre:

-   Dvidir data en *Train* y *Test*
-   Volver a ajustar modelo
-   Test Data Class Prediction
-   Test Data Class Probabilities
-   Preparación final de datos para evaluación
-   Evaluación del modelo (Confusion Matrix, Accuracy, Sensitivity, etc.)

## Librerías

```{r, message=F}
pacman::p_load(GLMMadaptive,
               tidymodels,
               tidyverse,
               kableExtra,
               interplot,
               margins,
               sjPlot,
               stargazer,
               httr,
               brm,
               car,
               lmtest,
               sandwich,
               texreg,
               visreg, 
               tinytex, 
               vcdExtra,
               margins,
               modelr,
               msm)

```

## data (ELSOC 2019 w4)

```{r}
#ELSOC 2017
url <- "https://github.com/rcantillan/ricantillan.rbind.io/raw/main/dat/ELSOC/ELSOC_W02_v3.00_R.RData"
response <- GET(url)
local_path <- "ELSOC_W02_v3.00_R.RData"
writeBin(response$content, local_path)
load("ELSOC_W02_v3.00_R.RData") #reemplazar por ruta local de descarga

#ELSOC 2016
url <- "https://github.com/rcantillan/ricantillan.rbind.io/raw/main/dat/ELSOC/ELSOC_W01_v4.01_R.RData"
response <- GET(url)
local_path <- "ELSOC_W01_v4.01_R.RData"
writeBin(response$content, local_path)
load("ELSOC_W01_v4.01_R.RData") 
```

## Construcción variables

### egonet (wide)

```{r}
egonet<-elsoc_2017 %>%
  #glimpse() %>%
  dplyr::select(7:24)

glimpse(egonet)
```

### data alteris (a formato long)

```{r}
columnas <- c("sexo", "edad", "educ", "relig", "ideol", "barrio", "relacion")
num_alters <- 5

alter_list <- list()

for (i in 1:num_alters) {
  alter_cols <- paste0("r13_", columnas, "_", sprintf("%02d", i))
  alter <- elsoc_2017 %>%
    dplyr::select(idencuesta, all_of(alter_cols)) %>%
    rename_with(~ columnas, alter_cols) %>%
    mutate(n = i)
  
  alter_list[[i]] <- alter
}

alteris <- bind_rows(alter_list)
alteris<-arrange(alteris, idencuesta)
kable(head(alteris, n=25))
```

### recode

```{r}
alteris$educ <-factor(Recode(alteris$educ ,"1=1;2:3=2;4=3;5=4;-888=NA;-999=NA"))
alteris$relig<-factor(Recode(alteris$relig,"1=1;2=2;3=3;4=4;5=5;-888=NA;-999=NA"))
alteris$ideol<-factor(Recode(alteris$ideol,"1=1;2=2;3=3;4=4;5=5;6=6;-888=NA;-999=NA"))
alteris$edad <-factor(Recode(alteris$edad ,"0:18=1;19:29=2;30:40=3;41:51=4;52:62=5;63:100=6;-888=NA;-999=NA"))
alteris$sexo <-factor(Recode(alteris$sexo ,"1=1;2=2;-888=NA;-999=NA"))
alteris$barrio<-factor(Recode(alteris$barrio ,"1=1;2=0;-888=NA;-999=NA"))
#alteris<-na.omit(alteris)   
```

### data egos (Entrevistados)

```{r}
asoc<-elsoc_2016%>%dplyr::select(idencuesta,c12_01,c12_02,c12_03,c12_04,c12_05,
                                 c12_06,c12_07,c12_08,c12_09)


egos <-elsoc_2017 %>%dplyr::select(idencuesta,ego_sexo=m0_sexo,ego_edad=m0_edad,
                                   ego_ideol=c15,ego_educ=m01,ego_relig=m38,ego_ideol=c15,
                                   t01,t02_01,t02_02,t02_03,t02_04,ponderador02)

egos<-left_join(egos,asoc, by="idencuesta")
egos <- as_tibble(egos)
```

Recodificamos las variables de la data de ego siguiendo el patrón de la data de alteris.

```{r}
egos$ego_educ <-factor(Recode(egos$ego_educ,"1:3=1;4:5=2;6:7=3;8:10=4;-999:-888=NA"))
egos$ego_relig<-factor(Recode(egos$ego_relig,"1=1;2=2;9=3;7:8=4;3:6=5;-999:-888=NA"))
egos$ego_ideol<-factor(Recode(egos$ego_ideol,"9:10=1;6:8=2;5=3;2:4=4;0:1=5;11:12=6;-999:-888=NA"))
#egos$ego_edad <-factor(Recode(egos$ego_edad,"0:18=1;19:29=2;30:40=3;41:51=4;52:62=5;63:100=6;-888=NA;-999=NA"))
egos$ego_sexo <-factor(Recode(egos$ego_sexo,"1=1;2=2;-888=NA;-999=NA"))
```

### Join

Con la función left_join agregamos la data de alteris y egos hacia el lado, en función del id de ego.

```{r}
obs<-left_join(egos,alteris, by="idencuesta")
obs[obs=="-999"] <- NA
obs[obs=="-888"] <- NA

```

### Crear variables independientes de interés

```{r}
# distancia 
obs <- obs %>%
  mutate(sexo_dist1 = ifelse(sexo == ego_sexo, 0, 1))%>%
  mutate(educ_dist1 = ifelse(educ == ego_educ, 0, 1))%>%
  mutate(ideol_dist1= ifelse(ideol== ego_ideol,0, 1))%>%
  mutate(relig_dist1= ifelse(relig== ego_relig,0, 1))%>%
  # índice compromiso barrial 
  mutate(neigh_attach=(t02_01+t02_02+t02_03+t02_04)/4)%>%
  # tipos de comportamiento asociativo
  mutate_at(vars(matches("c12")), ~ifelse(. < 2, 0, 1)) %>% 
  mutate(expresivas= c12_01+c12_02+c12_04)%>%
  mutate(instrument= c12_03+c12_05+c12_06+c12_07+c12_08)
```

### Variable dependiente (alter vecino)

```{r, message=FALSE}
x <- c("No es vecino", "Es vecino")

obs%>%
  filter(!is.na(barrio)) %>%  # Filtrar las filas donde barrio no sea NA
  ggplot(aes(x = barrio, fill = barrio)) +
  geom_bar(fill = "blue", alpha = 0.5) +
   geom_text(aes(label = scales::percent(..count../sum(..count..))), 
             color="white",
            stat = "count", 
            position = position_stack(vjust = 0.5), 
            size = 4) + # Agregar etiquetas de texto con porcentajes
  labs(title = "Alter es vecin@",
       x = "",
       y = "Frecuencia") +
  scale_x_discrete(labels=x) +
  theme_minimal()
```

### ICC

```{r}
obs$barrio<-as.factor(obs$barrio)
obs<-obs%>%drop_na(barrio)%>%mutate(barrio=case_when(barrio==1~1,TRUE~0))
obs$idencuesta<-as.factor(obs$idencuesta)

# calcular grado 
obs <- obs %>% group_by(idencuesta) %>% mutate(grado = n()) %>% ungroup()

# modelo
m_nulo <- mixed_model(barrio ~ 1, 
                      random =~ 1 | idencuesta, 
                      data=obs, 
                      family = binomial, 
                      nAGQ=11, 
                      iter_EM=60)

summary(m_nulo)
icc_result <- performance::icc(m_nulo)
icc_result
```

## Modelo de regresión logística

### Modelo 1

```{r}
m1<-glm(barrio~
          ego_sexo
        + ego_educ
        + ego_edad
        + expresivas
        + instrument
        + t01
        + neigh_attach, data = obs, family = "binomial")

summary(m1)
```

### Modelo 2

```{r}
m2<-glm(barrio~
          ego_sexo
        + ego_educ
        + ego_edad
        + sexo_dist1 
        + educ_dist1 
        + ideol_dist1
        + relig_dist1, data = obs, family = "binomial")

summary(m2)
```

### Modelo 3

```{r}
m3<-glm(barrio~
          ego_sexo
        + ego_educ
        + ego_edad
        + expresivas
        + instrument
        + t01 
        + neigh_attach
        + factor(sexo_dist1) 
        + factor(educ_dist1) 
        + factor(ideol_dist1)
        + factor(relig_dist1)
        + ego_educ*factor(educ_dist1), data = obs, family = "binomial")

summary(m3)
```

### SE robustos

```{r}
coeftest(m3, vcov = vcovHC(m3, type="HC1"))
```

### Tabla comparativa

```{r, results = "asis", message=FALSE, warning=FALSE}
stargazer(m1,m2,m3, style="ajs", type = 'html', single.row = TRUE)
```

### Ejemplo de interpretación: coeficiente (log odds)

Para variables "continuas": "Un incremento en ... los log odds de la formación de vínculos vecinales se incrementa (o decrece) en ...

Para Variables "categóricas": ejemplo, "tener un nivel educativo superior, en contraste con el nivel educativo básico, modifica los log odds de formas vínculos vecinales en -1.533"

### Ejemplo de interpretación II: odds

```{r}
exp(cbind(OR = coef(m3), confint(m3)))
```

Con la transformación exponencial (a OR) se puede decir, "con el incremento en una unidad de Edad del ego, se incrementan los odds (probabilidad) de que los vínculos de confidencia formados sean vecinales (versus la posibilidad de que no lo sean)

### Tidy model y plot de coeficientes con OR

```{r}
obs$barrio<-as.factor(obs$barrio)

tidy_m3<- logistic_reg() %>%
        # Set the engine
        set_engine("glm") %>%
        # Set the mode
        set_mode("classification") %>%
        # Fit the model
        fit(barrio~
          ego_sexo
        + ego_educ
        + ego_edad
        + expresivas
        + instrument
        + t01
        + neigh_attach
        + sexo_dist1 
        + educ_dist1 
        + ideol_dist1
        + relig_dist1
        + ego_educ*educ_dist1, data = obs)

# tidy(tidy_m3) #Summary Table

# data for plot. 
data_model_plot<-tidy(tidy_m3, exponentiate = FALSE, conf.int = TRUE) |> 
  mutate_if(is.numeric, round, 4) 
 # select(-std.error, -statistic)

glimpse(data_model_plot)
```

### Interpretación de las interacciones.

-   ego_educ2:educ_dist1: El odds ratio es aproximadamente 1.476. Esto significa que cuando la distancia educativa (educ_dist1) aumenta en una unidad y el nivel de educación es 2 (ego_educ2), las probabilidades de que la variable dependiente sea "1" en lugar de "0" se multiplican por 1.476.

-   ego_educ3:educ_dist1: El odds ratio es aproximadamente 2.065. De manera similar, cuando la distancia educativa aumenta en una unidad y el nivel de educación es 3 (ego_educ3), las probabilidades de que la variable dependiente sea "1" en lugar de "0" se multiplican por 2.065.

-   ego_educ4:educ_dist1: El odds ratio es aproximadamente 3.581. Cuando la distancia educativa aumenta en una unidad y el nivel de educación es 4 (ego_educ4), las probabilidades de que la variable dependiente sea "1" en lugar de "0" se multiplican por 3.581.

Estos odds ratios indican cómo cambian las probabilidades de éxito en comparación con un punto de referencia (en este caso, cuando la distancia educativa es cero y el nivel de educación es ego_educ1). Si el odds ratio es mayor que 1, indica un aumento en las probabilidades de éxito. Si es menor que 1, indica una disminución.

Por ejemplo, si ego_educ2:educ_dist1 es 1.476, entonces cuando la distancia educativa aumenta en una unidad y el nivel de educación es 2 (ego_educ2), las probabilidades de éxito son aproximadamente un 47.6% más altas en comparación con el punto de referencia.

### Plot

```{r warning=F}
data_model_plot <- data_model_plot %>%
  mutate(term= case_when(
    #term == "(Intercept)"~"(Intercept)",
    term == "ego_sexo2" ~ "sexo (ego)",
    term == "ego_educ2" ~ "Nivel educativo (media)",
    term == "ego_educ3" ~ "Nivel educativo (técnico)",
    term == "ego_educ4" ~ "Nivel educativo (superior)",
    term == "ego_edad +" ~ "Edad (ego)",
    term == "expresivas" ~ "Memb. Expresiva",
    term == "instrument" ~ "Memb. Instrumental",
    term == "t01" ~ "Confianza vecinal",
    term == "neigh_attach" ~ "comprom. barrio",
    term == "sexo_dist1" ~ "Sexo distancia",
    term == "educ_dist1" ~ "Educación distancia",
    term == "ideol_dist1" ~ "Ideología distancia",
    term == "relig_dist1" ~ "Religión distancia",
    term == "ego_educ2:educ_dist1" ~ "Nivel educativo medio (ego)*Educ. dist.",
    term == "ego_educ3:educ_dist1" ~ "Nivel educativo técnico (ego)*Educ. dist.",
    term == "ego_educ4:educ_dist1" ~ "Nivel educativo superior (ego)*Educ. dist.",
    # Agrega más condiciones según sea necesario
    TRUE ~ term  # Mantener otros valores sin cambios
  ))


data_model_plot %>%
  mutate(or=round(exp(estimate), 2))%>% # crear odds
  ggplot(aes(y = term, x = estimate, label = or)) +
  geom_point(aes(y = term, x=estimate), color= "blue", alpha = 0.5) +  
  geom_errorbarh(aes(xmax = conf.high, xmin = conf.low, height = .12), color ="blue", alpha = 0.5, size = 0.6) +  
  geom_vline(xintercept =0, linetype = "dashed") +
  scale_shape_manual(values = c(0,2,19)) +
  geom_text(size = 3.5, nudge_x = 2,vjust = -0.25) + 
  #facet_grid(.~y.level) +
  scale_x_continuous(limits=c(-5,5)) +
  theme_gray()+
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, size = 15),
        axis.title = element_text(size=10),
        axis.text.x = element_text(size=11),
        axis.text.y = element_text(size = 11),
        legend.text = element_text(size = 10),
        legend.title = element_text(face = "bold", size = 12)) +
  guides(pch=guide_legend(title="Patrones")) +
  ylab("") + 
  xlab("") +
  ggtitle("Coeficientes de regresión con OR") +
 # scale_y_discrete(limits=rev) +
  scale_y_discrete(expand=c(0.05, 0), limits = c("(Intercept)",
                              "sexo (ego)",
                              "Nivel educativo (media)",
                              "Nivel educativo (técnico)",
                              "Nivel educativo (superior)",
                              "Edad (ego)",
                              "Memb. Expresiva",
                              "Memb. Instrumental",
                              "Confianza vecinal", 
                              "comprom. barrio",
                              "Sexo distancia",
                              "Educación distancia",
                              "Ideología distancia",
                              "Religión distancia",
                              "Nivel educativo medio (ego)*Educ. dist.",
                              "Nivel educativo técnico (ego)*Educ. dist.",
                              "Nivel educativo superior (ego)*Educ. dist."))
```

### Bootstrap

El "bootstrap" es un método de remuestreo que permite estimar la distribución muestral de un estadístico a partir de los datos.

1.  Funciona tomando muestras aleatorias con reemplazo de los datos originales. Como es con reemplazo, cualquier observación de los datos originales puede aparecer repetida en esta muestra bootstrap

El tamaño de la muestra bootstrap es ser menor a N. Por ejemplo, N/2. Lo importante es que el tamaño de cada muestra bootstrap sea fijo. Por ejemplo, si la primera muestra es de tamaño N/2, las demás también serán de tamaño N/2. Esto se hace para que en el proceso de remuestreo bootstrap, las muestras sean comparables entre sí.

2.  Se calcula el estadístico de interés (media, desviación estándar, etc) para cada muestra bootstrap. Esto genera una distribución bootstrap del estadístico. La media y desviación estándar de la distribución bootstrap son usadas como estimadores puntual y de error estándar del parámetro poblacional.

3.  Se repiten los pasos 1 y 2 muchas veces, (ej. 1000). Cada vez se obtiene una muestra bootstrap de tamaño N y se calcula el estadístico en ella. Todos los valores del estadístico en las 1000 muestras bootstrap conforman su distribución bootstrap.

4.  Permite estimar intervalos de confianza sin asumir normalidad. Es útil con muestras pequeñas o distribuciones no normales.

5.  Puede usarse para validación cruzada, remuestreo, o estimar sesgo y varianza de modelo.

Podemos usar la función `bootstraps()` en el paquete `rsample` para muestrear. Primero, construimos 1000 réplicas de arranque de los datos, cada una de las cuales ha sido muestreada aleatoriamente con reemplazo. El objeto resultante es un rset, que es un marco de datos con una columna de objetos rsplit.

Un objeto `rsplit` tiene dos componentes principales: un conjunto de datos de análisis y un conjunto de datos de evaluación, accesibles mediante análisis (rsplit) y evaluación (rsplit) respectivamente. Para las muestras de arranque, el conjunto de datos de análisis es la muestra de arranque en sí y el conjunto de datos de evaluación consta de todas las muestras listas para usar.

```{r}
# segmentamos
set.seed(27)
boots <- bootstraps(obs, times = 1000, apparent = TRUE)
#boots
```

Creemos una función auxiliar para ajustar un modelo `logistic_reg()` en cada muestra de arranque y luego usemos `purrr::map()` para aplicar esta función a todas las muestras de arranque a la vez. De manera similar, creamos una columna de información de coeficientes ordenada al desanidar.

```{r}
# creamos función.
fit_logit_bootstrap <- function(split) {
  logistic_reg() %>%
        # Set the engine
        set_engine("glm") %>%
        # Set the mode
        set_mode("classification") %>%
    fit(barrio~
          ego_sexo
        + ego_educ
        + ego_edad
        + expresivas
        + instrument
        + t01
        + neigh_attach
        + sexo_dist1 
        + educ_dist1 
        + ideol_dist1
        + relig_dist1
        + ego_educ*educ_dist1, analysis(split), start = list(k = 1, b = 0))
}

# aplicamos función.
boot_models <-
  boots %>% 
  mutate(model = map(splits, fit_logit_bootstrap),
         coef_info = map(model, tidy))

# revisamos coeficientes.
boot_coefs <- 
  boot_models %>% 
  unnest(coef_info)
```

```{r}
head(boot_coefs)
```

### Intervalos de confianza (con gráficos)

```{r}
percentile_intervals <- int_pctl(boot_models, coef_info)
head(percentile_intervals)
```

```{r}
ggplot(boot_coefs, aes(estimate)) +
  geom_histogram(bins = 30) +
  facet_wrap( ~ term, scales = "free") +
  geom_vline(aes(xintercept = .lower), data = percentile_intervals, col = "blue") +
  geom_vline(aes(xintercept = .upper), data = percentile_intervals, col = "blue")
```


### Bootstrap 2: Aproximación alternativa para el cálculo de diferencias entre categorías de una variable 

```{r}
# modelo de interés
modelo1<-glm(barrio~ego_sexo + ego_educ + ego_edad, family=binomial(link="logit"), data=obs)

# función para cálculo de bootstrap
bs_beta2 <- function(x) {
data_b <- sample_n(obs,size=nrow(obs),replace=TRUE)
logit_b <- glm(barrio~ego_sexo + ego_educ + ego_edad, family=binomial(link="logit"), data=data_b)
grid <- obs %>% data_grid(ego_sexo,ego_educ=ego_educ, ego_edad = ego_edad,.model=modelo1)
newx <- grid %>% mutate(logit = predict(logit_b, newdata = grid), p_hat = 1/(1 + exp(-logit)))
diff_sexo <- newx$p_hat[2] - newx$p_hat[1]
return(diff_sexo)
}

# aplicamos 
nreps =1200
betas2_bs <- replicate(nreps,bs_beta2()); head(betas2_bs) 

# intervalo 
ci_beta2_bs <- quantile(betas2_bs, p=c(0.04,0.96))

# objeto para plot
betas2_bs <- replicate(nreps,bs_beta2())%>%as_tibble()

# plot
betas2_bs %>% ggplot(aes(x=value)) +
  geom_density(color="blue") +
  geom_vline(xintercept = -0.0013870315, color="green") +
  geom_vline(xintercept = -0.0001360474, color="green") +
  labs(x= "Diferencia entre mujer y hombre sobre probabilidad incluir a vecinos en las redes personales")
```



## Train y Test data

En esta sección trabajaremos con la idea de predicción. Por lo general, para realizar la predicción de una clasificación los datos completos se divide en un 75% que usa como "data train" y un 25% que se usa como "test data". El 75% de los datos de entrenamiento se utiliza para el entrenamiento del modelo, mientras que el 25% restante se utiliza para comprobar cómo se generalizó el modelo en un conjunto de datos de prueba o no vistos.

Para dividir los datos vamos a utilizar la función `inicial_split()` de la librería `tidymodels`. En esta, se deben especificar el nombre del objeto de datos, la proporción y un argumento de estrato. Al proporcionar su variable dependiente en el atributo estratos se realiza un muestreo estratificado. El muestreo estratificado es útil si su variable dependiente tiene un desequilibrio de clases.

El siguiente paso es llamar a las funciones de `entrenamiento()` y `prueba()` para guardar ambos conjuntos de datos (train y test).

```{r}
# seed
set.seed(123)

# delete na "barrio"
obs <- obs %>% drop_na(barrio)

# data split 
vecino_split <- initial_split(obs,
                              prop = 0.75,
                              strata = barrio) 
vecino_split
```

```{r}
# training data
vecino_train <- vecino_split %>% training()

# testing data
vecino_test <- vecino_split %>% testing()

# Número de filas 
nrow(vecino_train)
nrow(vecino_test)
```

A continuación ajustamos los modelos:

1.  Primero, utilizamos la fución `logistic_reg()`.
2.  Luego usamos la función `set_engine()` para indicar la familia del modelo.
3.  Usamos la función `set_mode()`, para indicar el tipo de modelo a utilizar. En este caso queremos clasificar positivos y negativos, razón por la cual es un modelo de clasificación.
4.  Espeicifamos el modelo con la función `fit()`
5.  Finalmente, generamos una tabla de resumen usando la función `tidy()` de la librería `broom` (que viene incorporada con la biblioteca tidymodels). Los coeficientes informados están en términos de log odds.

### Volver a ajustar modelo

```{r}
nm3<- logistic_reg() %>%
        set_engine("glm") %>%
        set_mode("classification") %>%
        fit(barrio~
          ego_sexo
        + ego_educ
        + ego_edad
        + expresivas
        + instrument
        + t01
        + neigh_attach
        + sexo_dist1 
        + educ_dist1 
        + ideol_dist1
        + relig_dist1
        + ego_educ*educ_dist1, data = vecino_train)

tidy(nm3)    
```

### OR

En el summery anterior la interpretación de los coeficientes en el término de probabilidades logarítmicas no tiene mucho sentido si el objetivo es la publicación o la divulgación. Para esto, es preferible usar OR. Las OR es el ratio de la probabilidad de que ocurra un evento a la de que el evento no ocurra. Cuando tomamos un ratio de dos de esas probabilidades, se llama Odds Ratio.

::: column-margin
$$ ODDS = \frac{Evento \; ocurre}{Evento \; No \; ocurre} = \frac{Probabilidad}{1-Probabilidad} $$

$$ OR = \frac{odds\;1}{odds\;2} $$

$$ OR \neq Probabilidad $$
:::

Los OR se pueden calcular con el exponente de los coeficientes estimados en el modelo anterior. Con `R` esto se puede hacer con la función `tidy()`, especificando el argumento `exponentiate=TRUE`.

```{r}
tidy(nm3, exponentiate = TRUE)
```

### Efectos marginales

En una regresión logística, el efecto marginal se refiere al cambio en la probabilidad de éxito (es decir, la categoría 1 de la variable dependiente) asociado con un cambio de una unidad en la variable independiente, manteniendo todas las demás variables constantes.

El cáculo de otras cantidades de interés puedes ser revisadas en @leeperInterpretingRegressionResults2017. Adcionalmente pueden visitar el siguiente [link](https://www.andrewheiss.com/blog/2022/05/20/marginalia/).

```{r}
me<-summary(margins(m3, variables = c("ego_educ")))
glimpse(me)
```

```{r}
me2 <- summary(margins(m3, at = list(educ_dist1 = c(0,1)), variables = "ego_educ"))
me2 %>% kbl(caption = "Efectos marginales") %>% kable_classic("hover", full_width = T)
```

```{r}
me2%>%
  ggplot(aes(x =factor, y= AME)) + 
  geom_point() + 
  geom_line(group="factor") +
  geom_errorbar(aes(ymin = lower, ymax = upper), alpha = 1, width=0.2)+
  facet_grid(.~ educ_dist1,
             labeller = as_labeller(c("0"='No distancia',
                                      "1"='Distancia'))) +
    scale_x_discrete(labels=c("ego_educ2" = "Media (ego)", 
                              "ego_educ3" = "Técnica (ego)", 
                              "ego_educ4" = "Superior (ego)"))+
  xlab("") +
  ylab("Average Marginal Effect (AME)")+
  theme(axis.ticks.y=element_blank(),
        legend.position = "right",
        plot.title = element_text(hjust = 0.5, size = 9),
        axis.title = element_text(size=10),
        axis.text.x = element_text(size=11),
        axis.text.y = element_text(size = 9),
        legend.text = element_text(size = 10),
        legend.title = element_text(face = "bold",
                                    size = 10)) 
```

### Test Data Class Prediction

```{r}
# Class predicha
pred_class <- predict(nm3,
                      new_data = vecino_test,
                      type = "class")

pred_class[1:20,]
```

### Test Data Class Probabilities

```{r}
# Predicción de probabilidades
pred_proba <- predict(nm3,
                      new_data = vecino_test,
                      type = "prob")

pred_proba[1:20,]
```

### Preparación final de datos para evaluación

```{r}
vecino_r <- vecino_test %>%
  dplyr::select(barrio) %>%
  bind_cols(pred_class, pred_proba)

vecino_r[1:20, ]
```

## Evaluación del modelo (Confusion Matrix, Accuracy, Sensitivity, etc.)

Generamos una matriz de confusión utilizando la función `conf_mat()`. En esta función se proporciona el data.frame final, es decir, `vecinos_r`, la columna de `truth`, es decir, si el alter es veicno (o viven en el mismo barrio) y la clase predicha (.pred_class) en el atributo `estimate`.

La matriz de confusión reveló que el conjunto de datos de prueba tiene 880 casos de muestra de observaciones positivas (1) y 788 casos de observaciones negativas (0). El modelo entrenado clasificó con precisión 571 clases positivas (1) y 454 negativas (0).

```{r}
conf_mat(vecino_r, truth = barrio,
         estimate = .pred_class)
```

### Otras métricas

Ejemplo:

**Precisión** responde a la pregunta ¿Cuántos de todos los positivos se clasificaron correctamente como positivos?

**F-measure** es una media armónica ponderada de "precisión" y "recall" con la mejor puntuación de 1 y la peor puntuación de 0. La puntuación transmite el equilibrio entre precisión y recuperación. La puntuación F es de aproximadamente 0.59, lo que indica que el modelo entrenado tiene una potencia de clasificación del 59 %.

**Matthews correlation coefficient (MCC)** se utiliza como medida de la calidad de un clasificador binario. El valor oscila entre −1 y +1. MCC: -1 indica total desacuerdo, MCC: 0 indica que no hay acuerdo, MCC: +1 indica agregación total.

```{r}
custom_metrics <- metric_set(accuracy, sens, precision, recall, f_meas, kap, mcc)
custom_metrics(vecino_r, truth = barrio, estimate = .pred_class)
```

ROC-AUC es una medida de rendimiento para el problema de clasificación en varios umbrales. ROC_AUC indica la capacidad del modelo de distinguir entre clases. El modelo de regresión logística entrenado tiene un ROC-AUC de 0,7, lo que indica un *pobre* rendimiento predictivo general.

```{r}
roc_auc(vecino_r, truth = barrio, .pred_0)
```

```{r}
vecino_r %>%
  roc_curve(truth = barrio, .pred_0) %>%
  autoplot()
```
